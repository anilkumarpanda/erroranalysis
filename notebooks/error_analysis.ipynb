{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Error Analysis for Tabular Data."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Platfrom information\n",
    "%load_ext watermark\n",
    "%watermark"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Import all libraries\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from raiwidgets import ErrorAnalysisDashboard\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from src.model import select_features\n",
    "from src.model import tune_parameters,show_model_results"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Package versions installed\n",
    "%watermark --iversions"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Read & Clean Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Read dataset.\n",
    "data = pd.read_csv('../data/heloc_dataset_v1.csv')\n",
    "\n",
    "# Data Cleaning based on Error analysis.\n",
    "data = data[data['NumSatisfactoryTrades']>=0]\n",
    "data = data[data['ExternalRiskEstimate']>=0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Split data into Train & Test Set.\n",
    "y = data['RiskPerformance'].apply(lambda x : 1 if 'Bad' in x else 0)\n",
    "print(f\"Class balance :\\n{y.value_counts(normalize=True)}\")\n",
    "X = data.drop(columns='RiskPerformance')\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=345,stratify=y)\n",
    "data_dict = {'xtrain': X_train, 'ytrain': y_train,'xtest' : X_test, 'ytest' : y_test}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feature Selection"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "selected_features,fs_plot = select_features(data=data_dict)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see that 5 features are most important, we will go ahead with only these ones.\n",
    "\n",
    "This also makes life easy to do error analysis."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Subset the dataset with the selected features.\n",
    "data_dict['xtrain'] = data_dict['xtrain'][selected_features]\n",
    "data_dict['xtest'] = data_dict['xtest'][selected_features]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = XGBClassifier()\n",
    "model_param = tune_parameters(data=data_dict,model=model)\n",
    "# Add monotonic constraints.\n",
    "model_param['monotone_constraints']=(-1,-1,-1,+1,-1)\n",
    "print(f\"Creating model with features : {model_param}\")\n",
    "clf = XGBClassifier(**model_param)\n",
    "model = show_model_results(data=data_dict,model=model)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "So it is `decent` model, now lets start to use the various error analysis method and see if we can do something and\n",
    "improve the model. \n",
    "\n",
    "## Error Analysis\n",
    "\n",
    "The error analysis library by Microsoft, deals with preddictions.\n",
    "\n",
    "Thus we will convert the probabilities to predictions, using the above output.\n",
    "0.57 seems to be a good threshold."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y_test_proba = model.predict_proba(data_dict['xtest'])[:,1]\n",
    "predictions = np.where(y_test_proba > 0.57, 1, 0)\n",
    "features = data_dict['xtrain'].columns\n",
    "ErrorAnalysisDashboard(dataset=data_dict['xtest'], true_y=data_dict['ytest'], features=features, pred_y=predictions);"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "After error analysis we see that our model does not perfrom well on ceratin sub-population. \n",
    "Once you know that, there are few things you can do a few things, one among them is model assertion. \n",
    "\n",
    "The main idea of an assertion is that you you define certain thresholds, value points for which the model has seen the data. Rest the model does not know, hence the output should say so. \n",
    "\n",
    "Let try model stacking with only the datapoints for which we this model is making a error. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from probatus.interpret import ShapModelInterpreter\n",
    "shap_interpreter = ShapModelInterpreter(model)\n",
    "feature_importance = shap_interpreter.fit_compute(\n",
    "    data_dict['xtrain'], \n",
    "    data_dict['xtest'], \n",
    "    data_dict['ytrain'],\n",
    "     data_dict['ytest'], approximate=False)\n",
    "shap_interpreter.plot('importance');"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We see that `ExternalRiskEstimate` is the most important feature. It also contributes to a lot of errors.\n",
    "\n",
    "Lets look at the data and if we can stop any anamolies."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ax = shap_interpreter.plot('dependence', target_columns=['ExternalRiskEstimate'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ax = shap_interpreter.plot('dependence', target_columns=['NumSatisfactoryTrades'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.2",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.2 64-bit ('ml_course': conda)"
  },
  "interpreter": {
   "hash": "840a8f90bab7f8aa7aca9b581783b6d463addd3704b569b9012f434dd16204f7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}