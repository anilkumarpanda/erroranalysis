{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering with Atom Package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets start by importing all the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all libraries\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from raiwidgets import ErrorAnalysisDashboard\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from src.model import select_features\n",
    "from src.model import tune_parameters,show_model_results,get_monotone_constraints\n",
    "from atom import ATOMClassifier\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read & Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read dataset.\n",
    "data = pd.read_csv('../data/heloc_dataset_v1.csv')\n",
    "\n",
    "# Data Cleaning based on Error analysis.\n",
    "data = data[data['NumSatisfactoryTrades']>=0]\n",
    "data = data[data['ExternalRiskEstimate']>=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into Train & Test Set.\n",
    "y = data['RiskPerformance'].apply(lambda x : 1 if 'Bad' in x else 0)\n",
    "print(f\"Class balance :\\n{y.value_counts(normalize=True)}\")\n",
    "X = data.drop(columns='RiskPerformance')\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=345,stratify=y)\n",
    "data_dict = {'xtrain': X_train, 'ytrain': y_train,'xtest' : X_test, 'ytest' : y_test}\n",
    "print(f\"Class balance for Train data :\\n{data_dict['ytrain'].value_counts(normalize=False)}\")\n",
    "print(f\"Class balance for Test data :\\n{data_dict['ytest'].value_counts(normalize=False)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature creation with ATOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset into atom\n",
    "atom = ATOMClassifier(data_dict['xtrain'], data_dict['ytrain'], test_size=0.2, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atom works with the concept of branches. Read [this story]() to learn more.\n",
    "Let us add 20 more features using the DFS set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atom.branch = \"dfs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atom.feature_generation(\n",
    "    strategy=\"dfs\",\n",
    "    n_features=20,\n",
    "    operators=[\"add\", \"mul\",\"sub\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the features, survive the feature selection methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform the data into a format that can be used existing code.\n",
    "X_train_new, y_train_new = atom.transform(data_dict['xtrain'], data_dict['ytrain'])\n",
    "X_test_new, y_test_new = atom.transform(data_dict['xtest'], data_dict['ytest'])\n",
    "# Update the data dictionary\n",
    "dfs_data_dict= {'xtrain': X_train_new, 'ytrain': y_train_new,'xtest' : X_test_new, 'ytest' : y_test_new}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features,fs_plot = select_features(data=dfs_data_dict,n_features=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset the dataset with the selected features.\n",
    "dfs_data_dict['xtrain'] = dfs_data_dict['xtrain'][selected_features]\n",
    "dfs_data_dict['xtest'] = dfs_data_dict['xtest'][selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier()\n",
    "model_param = tune_parameters(data=dfs_data_dict,model=model)\n",
    "# Add monotonic constraints.\n",
    "model_param['monotone_constraints']=get_monotone_constraints(data_dict=dfs_data_dict,target='RiskPerformance')\n",
    "print(f\"Creating model with features : {model_param}\")\n",
    "clf = XGBClassifier(**model_param)\n",
    "model = show_model_results(data=dfs_data_dict,model=clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atom.branch = \"gfg_from_master\"\n",
    "atom.feature_generation(\n",
    "    strategy=\"GFG\",\n",
    "    n_features=5,\n",
    "    operators=[\"add\", \"mul\",\"sub\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform the data into a format that can be used existing code.\n",
    "X_train_new, y_train_new = atom.transform(data_dict['xtrain'], data_dict['ytrain'])\n",
    "X_test_new, y_test_new = atom.transform(data_dict['xtest'], data_dict['ytest'])\n",
    "# Update the data dictionary\n",
    "gfg_data_dict= {'xtrain': X_train_new, 'ytrain': y_train_new,'xtest' : X_test_new, 'ytest' : y_test_new}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features,fs_plot = select_features(data=gfg_data_dict,n_features=13)\n",
    "# Subset the dataset with the selected features.\n",
    "gfg_data_dict['xtrain'] = gfg_data_dict['xtrain'][selected_features]\n",
    "gfg_data_dict['xtest'] = gfg_data_dict['xtest'][selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier()\n",
    "model_param = tune_parameters(data=gfg_data_dict,model=model)\n",
    "# Add monotonic constraints.\n",
    "model_param['monotone_constraints']=get_monotone_constraints(data_dict=gfg_data_dict,target='RiskPerformance')\n",
    "print(f\"Creating model with features : {model_param}\")\n",
    "clf = XGBClassifier(**model_param)\n",
    "model = show_model_results(data=gfg_data_dict,model=clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a5b7bd06b5a3e4368dd9531fff5bb5ceb47b896458e87cfaf0764c4d69ca71fa"
  },
  "kernelspec": {
   "display_name": "Python 3.6.2 ('ml_course')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
